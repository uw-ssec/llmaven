import logging
import os
from core.generator.language_model import LanguageModel

# Enable Hugging Face logs
import transformers
transformers.utils.logging.set_verbosity_info()  # Ensures logs appear

# Set logging level
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def test_language_model():
    logging.info("üöÄ Starting LanguageModel Debugging...")

    model_name = "allenai/OLMo-2-1124-7B-Instruct"  # Change this to your actual model name
    cache_path = os.path.join(os.path.dirname(__file__), "../models")
    model_path = os.path.join(cache_path, model_name.replace("/", "_"))

    logging.info(f"üìÇ Model cache path: {model_path}")

    # Initialize model
    try:
        logging.info("üü° Initializing LanguageModel...")
        model = LanguageModel(model_name=model_name)
        logging.info("‚úÖ LanguageModel initialized successfully.")
    except Exception as e:
        logging.error(f"‚ùå Error initializing LanguageModel: {e}")
        return

    # Load model with quantization
    try:
        logging.info("üü° Loading language model with 8-bit quantization...")
        model.load_language_model(quantization="8bit")
        logging.info("‚úÖ Model loaded successfully.")
    except Exception as e:
        logging.error(f"‚ùå Error loading model: {e}")
        return

    # Load Hugging Face pipeline
    try:
        logging.info("üü° Loading Hugging Face pipeline...")
        model.load_hg_pipeline()
        logging.info("‚úÖ Pipeline loaded successfully.")
    except Exception as e:
        logging.error(f"‚ùå Error loading pipeline: {e}")
        return

    # Run inference test
    prompt = "Tell me a fun fact about space."
    try:
        logging.info(f"üü° Running inference on prompt: {prompt}")
        response = model.inference(prompt)
        logging.info(f"‚úÖ Inference completed successfully.\nResponse: {response}")
    except Exception as e:
        logging.error(f"‚ùå Error during inference: {e}")
        return

if __name__ == "__main__":
    test_language_model()